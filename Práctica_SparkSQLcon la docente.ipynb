{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LADISLAOCOSTILLO/ARCHIVOSGIT/blob/main/Pr%C3%A1ctica_SparkSQLcon%20la%20docente.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Spark SQL**\n",
        "\n",
        "Spark SQL es un módulo de Apache Spark que facilita el procesamiento de datos estructurados mediante SQL. Permite trabajar con DataFrames y Dataset, ofreciendo una forma eficiente de realizar análisis de datos utilizando consultas SQL estándar o las APIs de Spark en lenguajes como Python."
      ],
      "metadata": {
        "id": "IP-yMbl-Jmj8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Instalación de PySpark en Google Colab"
      ],
      "metadata": {
        "id": "-wzjlDt7KfyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "#Consultar sitio para obtener el enlace de descarga más reciente https://www.apache.org/dyn/closer.lua/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "!pip install py4j\n",
        "\n",
        "import os\n",
        "import sys\n",
        "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\"\n",
        "\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()\n",
        "\n",
        "import pyspark\n",
        "\n",
        "from pyspark.sql import DataFrame, SparkSession\n",
        "from typing import List\n",
        "import pyspark.sql.types as T\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "spark= SparkSession \\\n",
        "       .builder \\\n",
        "       .appName(\"Our first Spark Example\") \\\n",
        "       .getOrCreate()\n",
        "\n",
        "spark"
      ],
      "metadata": {
        "id": "cOQaGU_gKnUr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 760
        },
        "outputId": "d6678a10-2f42-4a38-cfac-dced29f6957d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,853 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,161 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [5,103 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [5,290 kB]\n",
            "Hit:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,207 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,518 kB]\n",
            "Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,773 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,270 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,575 kB]\n",
            "Fetched 34.1 MB in 3s (9,965 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "36 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "tar: spark-3.2.1-bin-hadoop3.2.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.11/dist-packages (0.10.9.7)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x791479fe9dd0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://6c1b345bb90e:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Our first Spark Example</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "id": "jmyG69oULk0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "2b3bb0ee-c07b-47ba-bbea-ef5293e981a4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x791479fe9dd0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://6c1b345bb90e:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Our first Spark Example</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Leer Data COVID-19"
      ],
      "metadata": {
        "id": "xfM070GyOZZz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se utiliza un conjunto de datos disponibles públicamente en formato CSV. Rastreador de COVID-19 es un proyecto de análisis de datos basado en Python que rastrea los casos, muertes y tendencias de COVID-19 en países seleccionados utilizando datos reales de Our World in Data (OWID)."
      ],
      "metadata": {
        "id": "bgTzF68KOmoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "path = \"https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/owid-covid-data.csv\"\n",
        "req = requests.get(path)\n",
        "url_content = req.content\n",
        "\n",
        "csv_file_name = 'owid-covid-data.csv'\n",
        "csv_file = open(csv_file_name, 'wb')\n",
        "\n",
        "csv_file.write(url_content)\n",
        "csv_file.close()\n",
        "\n",
        "df = spark.read.csv('/content/'+csv_file_name, header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "PH_i5W1dO2b7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El módulo SQL es muy accesible para interactuar con los datos mientras se sigue usando Spark. Es básicamente la misma sintaxis SQL."
      ],
      "metadata": {
        "id": "42D-oo5TPQeE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creación de una tabla a partir del marco de datos\n",
        "df.createOrReplaceTempView(\"covid_data\") #Vista temporal\n",
        "# df.saveAsTable(\"covid_data\") #Guardar como una tabla\n",
        "# df.write.mode(\"overwrite\").saveAsTable(\"covid_data\") #Guardar como tabla y sobrescribir la tabla si existe"
      ],
      "metadata": {
        "id": "v9LdXghOPkYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "groupDF = spark.sql(\"SELECT location, count(*) from covid_data group by location\")\n",
        "groupDF.show()"
      ],
      "metadata": {
        "id": "AX-_20drP-oj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dd2b68e-777e-423f-ce7d-5a56a8b54c96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------+\n",
            "|            location|count(1)|\n",
            "+--------------------+--------+\n",
            "|                Chad|    1674|\n",
            "|            Anguilla|    1674|\n",
            "|            Kiribati|    1674|\n",
            "|              Guyana|    1674|\n",
            "|             Eritrea|    1674|\n",
            "|              Jersey|    1674|\n",
            "|            Djibouti|    1674|\n",
            "|                Fiji|    1674|\n",
            "|                Iraq|    1674|\n",
            "|              Europe|    1684|\n",
            "|             Germany|    1674|\n",
            "|             Comoros|    1674|\n",
            "|         Afghanistan|    1674|\n",
            "|            Cambodia|    1674|\n",
            "|High-income count...|    3026|\n",
            "|              Jordan|    1674|\n",
            "|              France|    1674|\n",
            "|              Greece|    1674|\n",
            "|              Kosovo|    1674|\n",
            "|              Africa|    1674|\n",
            "+--------------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. En este caso revisamos el siguiente conjunto de datos que viene con la sesión de Google Colab"
      ],
      "metadata": {
        "id": "-nkVfzjQQZ1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv(\"/content/sample_data/california_housing_train.csv\", header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "xgEnSL-oQuG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "id": "jdeipX0lQ5qz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "404bee83-1dd4-4d4c-e809-76371308b649"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- longitude: double (nullable = true)\n",
            " |-- latitude: double (nullable = true)\n",
            " |-- housing_median_age: double (nullable = true)\n",
            " |-- total_rooms: double (nullable = true)\n",
            " |-- total_bedrooms: double (nullable = true)\n",
            " |-- population: double (nullable = true)\n",
            " |-- households: double (nullable = true)\n",
            " |-- median_income: double (nullable = true)\n",
            " |-- median_house_value: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Imprimir N filas\n",
        "df.show(5)"
      ],
      "metadata": {
        "id": "Zjl2az3GQ-Ui",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4b6cd36-459e-4b7c-e7f8-08150cc2c728"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|  -114.31|   34.19|              15.0|     5612.0|        1283.0|    1015.0|     472.0|       1.4936|           66900.0|\n",
            "|  -114.47|    34.4|              19.0|     7650.0|        1901.0|    1129.0|     463.0|         1.82|           80100.0|\n",
            "|  -114.56|   33.69|              17.0|      720.0|         174.0|     333.0|     117.0|       1.6509|           85700.0|\n",
            "|  -114.57|   33.64|              14.0|     1501.0|         337.0|     515.0|     226.0|       3.1917|           73400.0|\n",
            "|  -114.57|   33.57|              20.0|     1454.0|         326.0|     624.0|     262.0|        1.925|           65500.0|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.count()"
      ],
      "metadata": {
        "id": "YLGUJ7IoRHLC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "253593fe-9378-4d45-90f4-66eb945eb07c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17000"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(\"housing_median_age\",\"total_rooms\").show(5)"
      ],
      "metadata": {
        "id": "vc4slHZNRIWy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d186c5d1-65e4-4683-c116-ae19c0b5037e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+-----------+\n",
            "|housing_median_age|total_rooms|\n",
            "+------------------+-----------+\n",
            "|              15.0|     5612.0|\n",
            "|              19.0|     7650.0|\n",
            "|              17.0|      720.0|\n",
            "|              14.0|     1501.0|\n",
            "|              20.0|     1454.0|\n",
            "+------------------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().show()"
      ],
      "metadata": {
        "id": "Ru5BAZ_9ROFr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5f3ed08-f40a-48f6-b1d7-5c881d722bee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------------------+------------------+------------------+-----------------+-----------------+------------------+-----------------+------------------+------------------+\n",
            "|summary|          longitude|          latitude|housing_median_age|      total_rooms|   total_bedrooms|        population|       households|     median_income|median_house_value|\n",
            "+-------+-------------------+------------------+------------------+-----------------+-----------------+------------------+-----------------+------------------+------------------+\n",
            "|  count|              17000|             17000|             17000|            17000|            17000|             17000|            17000|             17000|             17000|\n",
            "|   mean|-119.56210823529375|  35.6252247058827| 28.58935294117647|2643.664411764706|539.4108235294118|1429.5739411764705|501.2219411764706| 3.883578100000021|207300.91235294117|\n",
            "| stddev| 2.0051664084260357|2.1373397946570867|12.586936981660406|2179.947071452777|421.4994515798648| 1147.852959159527|384.5208408559016|1.9081565183791036|115983.76438720895|\n",
            "|    min|            -124.35|             32.54|               1.0|              2.0|              1.0|               3.0|              1.0|            0.4999|           14999.0|\n",
            "|    max|            -114.31|             41.95|              52.0|          37937.0|           6445.0|           35682.0|           6082.0|           15.0001|          500001.0|\n",
            "+-------+-------------------+------------------+------------------+-----------------+-----------------+------------------+-----------------+------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select('total_rooms').distinct().show()"
      ],
      "metadata": {
        "id": "LeEeAu-vRRYi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3b4cc2a-6d68-456e-b453-84e4086193b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|total_rooms|\n",
            "+-----------+\n",
            "|      934.0|\n",
            "|     3980.0|\n",
            "|     4142.0|\n",
            "|      596.0|\n",
            "|     1761.0|\n",
            "|     5983.0|\n",
            "|     2815.0|\n",
            "|     6433.0|\n",
            "|      299.0|\n",
            "|     2734.0|\n",
            "|      769.0|\n",
            "|     1051.0|\n",
            "|     7554.0|\n",
            "|     4066.0|\n",
            "|     2862.0|\n",
            "|     3597.0|\n",
            "|      692.0|\n",
            "|      720.0|\n",
            "|     1765.0|\n",
            "|     2523.0|\n",
            "+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "test = df.groupBy('total_rooms').agg(F.sum('housing_median_age'))"
      ],
      "metadata": {
        "id": "YD1uHv6IRSXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.toPandas()"
      ],
      "metadata": {
        "id": "vN9da027RcHb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "5de63dd7-e478-4036-9f74-cf329c0106a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      total_rooms  sum(housing_median_age)\n",
              "0           934.0                    135.0\n",
              "1          3980.0                     25.0\n",
              "2          4142.0                     37.0\n",
              "3           596.0                     25.0\n",
              "4          1761.0                    154.0\n",
              "...           ...                      ...\n",
              "5528       3620.0                     18.0\n",
              "5529        947.0                     62.0\n",
              "5530        710.0                     52.0\n",
              "5531         91.0                     43.0\n",
              "5532       5457.0                     21.0\n",
              "\n",
              "[5533 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7c37bd96-711f-4243-85d1-faecdfd8f6c9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>sum(housing_median_age)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>934.0</td>\n",
              "      <td>135.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3980.0</td>\n",
              "      <td>25.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4142.0</td>\n",
              "      <td>37.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>596.0</td>\n",
              "      <td>25.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1761.0</td>\n",
              "      <td>154.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5528</th>\n",
              "      <td>3620.0</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5529</th>\n",
              "      <td>947.0</td>\n",
              "      <td>62.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5530</th>\n",
              "      <td>710.0</td>\n",
              "      <td>52.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5531</th>\n",
              "      <td>91.0</td>\n",
              "      <td>43.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5532</th>\n",
              "      <td>5457.0</td>\n",
              "      <td>21.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5533 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c37bd96-711f-4243-85d1-faecdfd8f6c9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7c37bd96-711f-4243-85d1-faecdfd8f6c9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7c37bd96-711f-4243-85d1-faecdfd8f6c9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-36ab7194-57e5-4dff-b088-4c4afe3485d0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-36ab7194-57e5-4dff-b088-4c4afe3485d0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-36ab7194-57e5-4dff-b088-4c4afe3485d0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"test\",\n  \"rows\": 5533,\n  \"fields\": [\n    {\n      \"column\": \"total_rooms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3256.9556196835583,\n        \"min\": 2.0,\n        \"max\": 37937.0,\n        \"num_unique_values\": 5533,\n        \"samples\": [\n          14414.0,\n          2884.0,\n          5623.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sum(housing_median_age)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 81.92062654575412,\n        \"min\": 2.0,\n        \"max\": 539.0,\n        \"num_unique_values\": 373,\n        \"samples\": [\n          236.0,\n          66.0,\n          101.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Contar y eliminar valores faltantes\n",
        "\n",
        "df.select([F.count(F.when(F.isnull(c), c)).alias(c) for c in df.columns]).show()"
      ],
      "metadata": {
        "id": "zyYKgXHPRjEC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18beb797-9cfe-46d4-e3ec-2ae5b46a8036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|        0|       0|                 0|          0|             0|         0|         0|            0|                 0|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creación de un marco de datos de prueba de Spark"
      ],
      "metadata": {
        "id": "Ky0_JTgV0OoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "        ('John','Smith',1),\n",
        "        ('Jane','Smith',2),\n",
        "        ('Jonas','Smith',3),\n",
        "]\n",
        "\n",
        "columns = [\"firstname\",\"middlename\",\"ID\"]\n",
        "df = spark.createDataFrame(data, columns)"
      ],
      "metadata": {
        "id": "f8l4aOOt0j7g"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "pDvoKcQL1A0f",
        "outputId": "97574157-0ade-4cad-da5d-57ab8265481b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[firstname: string, middlename: string, ID: bigint]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spark Tips\n",
        "Esta es una colección de fragmentos de código para tareas comunes o complejas."
      ],
      "metadata": {
        "id": "euHkngY_1txX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Marco de datos de Pandas a marco de datos de Spark"
      ],
      "metadata": {
        "id": "c3eu9mhE28E-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.DataFrame(np.random.randint(100,size=(1000, 3)),columns=['A','B','C'])\n",
        "spark_df = spark.createDataFrame(df)\n",
        "spark_df.show()"
      ],
      "metadata": {
        "id": "hAKXfz2w2_ku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b41d3e5-e804-490a-8924-b12cf2ff6492"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+---+\n",
            "|  A|  B|  C|\n",
            "+---+---+---+\n",
            "| 12| 28| 20|\n",
            "| 71|  2| 25|\n",
            "| 83| 79|  4|\n",
            "|  0|  0|  3|\n",
            "| 40| 16| 31|\n",
            "| 19| 66| 77|\n",
            "| 87| 68| 17|\n",
            "|  0| 94| 31|\n",
            "| 75| 57| 47|\n",
            "| 89| 52| 30|\n",
            "| 75| 73| 47|\n",
            "| 56| 46| 27|\n",
            "| 24| 27| 32|\n",
            "| 19| 97| 68|\n",
            "| 58| 34| 34|\n",
            "| 64| 66| 64|\n",
            "|  9| 51| 58|\n",
            "| 50| 74| 27|\n",
            "| 12| 67| 89|\n",
            "| 96| 61| 74|\n",
            "+---+---+---+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Convertir columnas de objeto en un marco de datos de pandas en una cadena\n",
        "#for i in df.select_dtypes(include='object').columns.tolist():\n",
        "#\tdf[i] = df[i].astype(str)\n",
        "\n",
        "#Reemplazar nan y \"None\" en pandas dataframe a null en el marco de datos de spark\n",
        "#spark_df = spark.createDataFrame(df).replace('None', None).replace(float('nan'), None)"
      ],
      "metadata": {
        "id": "IYWmgVoS3PN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Funciones ventana SQL\n",
        "En SQL, las funciones ventana (o funciones analíticas) son funciones que realizan cálculos en un conjunto de filas relacionadas con la fila actual, sin colapsar las filas en una sola fila de salida (a diferencia de las funciones de agregación regulares con GROUP BY)."
      ],
      "metadata": {
        "id": "ae9HPqbt5P_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "        (1,'2021-01-01 10:00:00'),\n",
        "        (1,'2021-01-01 11:00:00'),\n",
        "        (1,'2021-01-01 12:00:00'),\n",
        "        (2,'2021-01-01 12:00:00'),\n",
        "        (2,'2021-01-01 13:00:00'),\n",
        "        (2,'2021-01-01 14:00:00'),\n",
        "]\n",
        "\n",
        "columns = [\"id\",\"datetime\"]\n",
        "df = spark.createDataFrame(data=data, schema = columns)\n",
        "df.createOrReplaceTempView(\"window_test\")\n",
        "df.show()"
      ],
      "metadata": {
        "id": "CBs_RoxE5weR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e7cf5a46-a6d4-45ac-ca72-16dd4833502b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------------+\n",
            "| id|           datetime|\n",
            "+---+-------------------+\n",
            "|  1|2021-01-01 10:00:00|\n",
            "|  1|2021-01-01 11:00:00|\n",
            "|  1|2021-01-01 12:00:00|\n",
            "|  2|2021-01-01 12:00:00|\n",
            "|  2|2021-01-01 13:00:00|\n",
            "|  2|2021-01-01 14:00:00|\n",
            "+---+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Seleccionando min y max por un Grupo específico\n",
        "spark.sql('''\n",
        "Select\n",
        "  id,\n",
        "\n",
        "  max(datetime) OVER (Partition BY id ORDER BY datetime) as max_date,\n",
        "  min(datetime) OVER (Partition BY id ORDER BY datetime) as min_date,\n",
        "\n",
        "  ROW_NUMBER() OVER (Partition BY id ORDER BY datetime) as row_number\n",
        "\n",
        "  FROM window_test\n",
        "\n",
        "''').show()"
      ],
      "metadata": {
        "id": "bwgC34uu6Mif",
        "outputId": "e4983cde-8ddb-4d9c-9276-e774f984ec1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------------+-------------------+----------+\n",
            "| id|           max_date|           min_date|row_number|\n",
            "+---+-------------------+-------------------+----------+\n",
            "|  1|2021-01-01 10:00:00|2021-01-01 10:00:00|         1|\n",
            "|  1|2021-01-01 11:00:00|2021-01-01 10:00:00|         2|\n",
            "|  1|2021-01-01 12:00:00|2021-01-01 10:00:00|         3|\n",
            "|  2|2021-01-01 12:00:00|2021-01-01 12:00:00|         1|\n",
            "|  2|2021-01-01 13:00:00|2021-01-01 12:00:00|         2|\n",
            "|  2|2021-01-01 14:00:00|2021-01-01 12:00:00|         3|\n",
            "+---+-------------------+-------------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleccionar el número de fila o el rango de orden para cada fila dentro de una agrupación específica.\n",
        "# Esto es ideal para subclasificaciones en una tabla.\n",
        "\n",
        "spark.sql('''\n",
        "Select\n",
        "  id,\n",
        "  datetime,\n",
        "\n",
        "  ROW_NUMBER() OVER (Partition BY id ORDER BY datetime) as row_number\n",
        "\n",
        "  FROM window_test\n",
        "\n",
        "''').show()"
      ],
      "metadata": {
        "id": "elKB8-Pj6ca2",
        "outputId": "c1b15843-5a93-4082-82c8-cadf187ae8b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------------+----------+\n",
            "| id|           datetime|row_number|\n",
            "+---+-------------------+----------+\n",
            "|  1|2021-01-01 10:00:00|         1|\n",
            "|  1|2021-01-01 11:00:00|         2|\n",
            "|  1|2021-01-01 12:00:00|         3|\n",
            "|  2|2021-01-01 12:00:00|         1|\n",
            "|  2|2021-01-01 13:00:00|         2|\n",
            "|  2|2021-01-01 14:00:00|         3|\n",
            "+---+-------------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# De-duplicated data: Desduplicar datos devolviendo la fila actualizada más recientemente mediante una función de ventana"
      ],
      "metadata": {
        "id": "FFXN06x_64jG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "        (1,'2021-01-01',100,'A'),\n",
        "        (1,'2021-01-31',105,'A'),\n",
        "        (2,'2021-02-04',160,'B'),\n",
        "        (2,'2021-02-07',145,'B'),\n",
        "]\n",
        "\n",
        "columns = [\"id\",\"date\",\"score\",\"type\"]\n",
        "df = spark.createDataFrame(data=data, schema = columns)\n",
        "df.createOrReplaceTempView(\"window_test\")\n",
        "df.show()"
      ],
      "metadata": {
        "id": "VamvhkvQ7MoW",
        "outputId": "2f4ba6cc-6a3c-47d2-d34f-a71cdfa274b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+-----+----+\n",
            "| id|      date|score|type|\n",
            "+---+----------+-----+----+\n",
            "|  1|2021-01-01|  100|   A|\n",
            "|  1|2021-01-31|  105|   A|\n",
            "|  2|2021-02-04|  160|   B|\n",
            "|  2|2021-02-07|  145|   B|\n",
            "+---+----------+-----+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = spark.sql(\"\"\"\n",
        "WITH T AS (\n",
        "  SELECT\n",
        "  *,\n",
        "  ROW_NUMBER() OVER (PARTITION BY id ORDER BY date DESC) AS version_number\n",
        "  FROM window_test\n",
        ")\n",
        "\n",
        "SELECT * FROM T WHERE version_number = 1;\n",
        "\n",
        "\"\"\")\n",
        "\n",
        "df2.show()"
      ],
      "metadata": {
        "id": "6Iiu2_wJ7RMO",
        "outputId": "26141dca-e4b2-4eeb-9c8d-7501643c04db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+-----+----+--------------+\n",
            "| id|      date|score|type|version_number|\n",
            "+---+----------+-----+----+--------------+\n",
            "|  1|2021-01-31|  105|   A|             1|\n",
            "|  2|2021-02-07|  145|   B|             1|\n",
            "+---+----------+-----+----+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "  SELECT\n",
        "  *,\n",
        "  SUM(score) OVER (PARTITION by type ORDER BY date) as score_cumulative\n",
        "  FROM window_test\n",
        "\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "id": "Q92iV1NX7U6W",
        "outputId": "328d6674-f104-4aef-b9da-491e682144e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+-----+----+----------------+\n",
            "| id|      date|score|type|score_cumulative|\n",
            "+---+----------+-----+----+----------------+\n",
            "|  1|2021-01-01|  100|   A|             100|\n",
            "|  1|2021-01-31|  105|   A|             205|\n",
            "|  2|2021-02-04|  160|   B|             160|\n",
            "|  2|2021-02-07|  145|   B|             305|\n",
            "+---+----------+-----+----+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Limitar el número de resultados por función de ventana de grupo"
      ],
      "metadata": {
        "id": "GN3LwEFC7Znm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.DataFrame(\n",
        "np.hstack((\n",
        "    np.random.randint(1,5,size=(100000, 1)),\n",
        "    np.random.randint(100,size=(100000, 1))\n",
        "))\n",
        ", columns=['company_id', 'number'])\n",
        "\n",
        "dff = spark.createDataFrame(df)\n",
        "dff.createOrReplaceTempView(\"window_test_limits\")"
      ],
      "metadata": {
        "id": "5W9mscmK7kLH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "WITH T AS (\n",
        "  SELECT\n",
        "    company_id,\n",
        "    number,\n",
        "    ROW_NUMBER() OVER (PARTITION BY company_id ORDER BY number) AS row_number\n",
        "  FROM window_test_limits\n",
        "    )\n",
        "\n",
        "SELECT * FROM T WHERE row_number <= 100\n",
        "\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "id": "NrTbAFKb7pG-",
        "outputId": "859774a7-59a7-43f6-d1d4-e7c7d8b511ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------+----------+\n",
            "|company_id|number|row_number|\n",
            "+----------+------+----------+\n",
            "|         1|     0|         1|\n",
            "|         1|     0|         2|\n",
            "|         1|     0|         3|\n",
            "|         1|     0|         4|\n",
            "|         1|     0|         5|\n",
            "|         1|     0|         6|\n",
            "|         1|     0|         7|\n",
            "|         1|     0|         8|\n",
            "|         1|     0|         9|\n",
            "|         1|     0|        10|\n",
            "|         1|     0|        11|\n",
            "|         1|     0|        12|\n",
            "|         1|     0|        13|\n",
            "|         1|     0|        14|\n",
            "|         1|     0|        15|\n",
            "|         1|     0|        16|\n",
            "|         1|     0|        17|\n",
            "|         1|     0|        18|\n",
            "|         1|     0|        19|\n",
            "|         1|     0|        20|\n",
            "+----------+------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calcular una media móvil de 7 días"
      ],
      "metadata": {
        "id": "x6Hul2KE7uve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(pd.date_range('1/1/2022','1/31/2022',freq='D'), columns=['date'])\n",
        "import random\n",
        "df['company_id'] = 1\n",
        "df['number'] = df.apply(lambda x: random.randint(0,100), axis = 1)\n",
        "\n",
        "dff = spark.createDataFrame(df)\n",
        "dff.createOrReplaceTempView(\"window_data\")\n",
        "\n",
        "dff.show()"
      ],
      "metadata": {
        "id": "LRLveZBO8FP2",
        "outputId": "12459f9e-2301-443f-a956-76053282ff3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+----------+------+\n",
            "|               date|company_id|number|\n",
            "+-------------------+----------+------+\n",
            "|2022-01-01 00:00:00|         1|    62|\n",
            "|2022-01-02 00:00:00|         1|    88|\n",
            "|2022-01-03 00:00:00|         1|    56|\n",
            "|2022-01-04 00:00:00|         1|    57|\n",
            "|2022-01-05 00:00:00|         1|    81|\n",
            "|2022-01-06 00:00:00|         1|    45|\n",
            "|2022-01-07 00:00:00|         1|    19|\n",
            "|2022-01-08 00:00:00|         1|    50|\n",
            "|2022-01-09 00:00:00|         1|    38|\n",
            "|2022-01-10 00:00:00|         1|    51|\n",
            "|2022-01-11 00:00:00|         1|    45|\n",
            "|2022-01-12 00:00:00|         1|    67|\n",
            "|2022-01-13 00:00:00|         1|     4|\n",
            "|2022-01-14 00:00:00|         1|    83|\n",
            "|2022-01-15 00:00:00|         1|     4|\n",
            "|2022-01-16 00:00:00|         1|    73|\n",
            "|2022-01-17 00:00:00|         1|    77|\n",
            "|2022-01-18 00:00:00|         1|    46|\n",
            "|2022-01-19 00:00:00|         1|    33|\n",
            "|2022-01-20 00:00:00|         1|     7|\n",
            "+-------------------+----------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT\n",
        "  date,\n",
        "  company_id,\n",
        "  number,\n",
        "  AVG(number) OVER (PARTITION BY company_id ORDER BY date ASC RANGE BETWEEN INTERVAL 6 DAYS PRECEDING AND CURRENT ROW) as last_7_day_avg\n",
        "FROM window_data\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "id": "fFuVFSSO8H-e",
        "outputId": "3a74dffd-5d5d-417c-a717-c00fc7094486",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+----------+------+------------------+\n",
            "|               date|company_id|number|    last_7_day_avg|\n",
            "+-------------------+----------+------+------------------+\n",
            "|2022-01-01 00:00:00|         1|    62|              62.0|\n",
            "|2022-01-02 00:00:00|         1|    88|              75.0|\n",
            "|2022-01-03 00:00:00|         1|    56| 68.66666666666667|\n",
            "|2022-01-04 00:00:00|         1|    57|             65.75|\n",
            "|2022-01-05 00:00:00|         1|    81|              68.8|\n",
            "|2022-01-06 00:00:00|         1|    45| 64.83333333333333|\n",
            "|2022-01-07 00:00:00|         1|    19|58.285714285714285|\n",
            "|2022-01-08 00:00:00|         1|    50| 56.57142857142857|\n",
            "|2022-01-09 00:00:00|         1|    38| 49.42857142857143|\n",
            "|2022-01-10 00:00:00|         1|    51|48.714285714285715|\n",
            "|2022-01-11 00:00:00|         1|    45|              47.0|\n",
            "|2022-01-12 00:00:00|         1|    67|              45.0|\n",
            "|2022-01-13 00:00:00|         1|     4|39.142857142857146|\n",
            "|2022-01-14 00:00:00|         1|    83|48.285714285714285|\n",
            "|2022-01-15 00:00:00|         1|     4|41.714285714285715|\n",
            "|2022-01-16 00:00:00|         1|    73|46.714285714285715|\n",
            "|2022-01-17 00:00:00|         1|    77| 50.42857142857143|\n",
            "|2022-01-18 00:00:00|         1|    46| 50.57142857142857|\n",
            "|2022-01-19 00:00:00|         1|    33|45.714285714285715|\n",
            "|2022-01-20 00:00:00|         1|     7|46.142857142857146|\n",
            "+-------------------+----------+------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usuarios activos mensualmente"
      ],
      "metadata": {
        "id": "tdkLXW0k8Tt2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(pd.date_range('1/1/2022','1/31/2022',freq='D'), columns=['login_date'])\n",
        "import random\n",
        "df['company_id'] = 1\n",
        "df['user_id'] = df.apply(lambda x: random.randint(0,3), axis = 1)\n",
        "\n",
        "dff = spark.createDataFrame(df)\n",
        "dff.createOrReplaceTempView(\"users_data\")\n",
        "\n",
        "dff.show()"
      ],
      "metadata": {
        "id": "QBjKGB7v8Wy2",
        "outputId": "1ee1bf14-0346-486a-ede3-d2aca7e0b420",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+----------+-------+\n",
            "|         login_date|company_id|user_id|\n",
            "+-------------------+----------+-------+\n",
            "|2022-01-01 00:00:00|         1|      2|\n",
            "|2022-01-02 00:00:00|         1|      3|\n",
            "|2022-01-03 00:00:00|         1|      1|\n",
            "|2022-01-04 00:00:00|         1|      2|\n",
            "|2022-01-05 00:00:00|         1|      0|\n",
            "|2022-01-06 00:00:00|         1|      3|\n",
            "|2022-01-07 00:00:00|         1|      0|\n",
            "|2022-01-08 00:00:00|         1|      1|\n",
            "|2022-01-09 00:00:00|         1|      3|\n",
            "|2022-01-10 00:00:00|         1|      1|\n",
            "|2022-01-11 00:00:00|         1|      1|\n",
            "|2022-01-12 00:00:00|         1|      3|\n",
            "|2022-01-13 00:00:00|         1|      1|\n",
            "|2022-01-14 00:00:00|         1|      1|\n",
            "|2022-01-15 00:00:00|         1|      2|\n",
            "|2022-01-16 00:00:00|         1|      1|\n",
            "|2022-01-17 00:00:00|         1|      0|\n",
            "|2022-01-18 00:00:00|         1|      2|\n",
            "|2022-01-19 00:00:00|         1|      0|\n",
            "|2022-01-20 00:00:00|         1|      0|\n",
            "+-------------------+----------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Revisar esta transformación\n",
        "spark.sql(\"\"\"\n",
        "SELECT\n",
        "  login_date,\n",
        "  COUNT(user_id) OVER (PARTITION BY login_date ORDER BY login_date ASC RANGE BETWEEN INTERVAL 30 DAYS PRECEDING AND CURRENT ROW) AS monthly_active_users\n",
        "  FROM users_data\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "id": "_hmMqeXx8brO",
        "outputId": "45a181ae-e9c1-4290-b0c0-20a6ce896510",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------------+\n",
            "|         login_date|monthly_active_users|\n",
            "+-------------------+--------------------+\n",
            "|2022-01-01 00:00:00|                   1|\n",
            "|2022-01-02 00:00:00|                   1|\n",
            "|2022-01-03 00:00:00|                   1|\n",
            "|2022-01-04 00:00:00|                   1|\n",
            "|2022-01-05 00:00:00|                   1|\n",
            "|2022-01-06 00:00:00|                   1|\n",
            "|2022-01-07 00:00:00|                   1|\n",
            "|2022-01-08 00:00:00|                   1|\n",
            "|2022-01-09 00:00:00|                   1|\n",
            "|2022-01-10 00:00:00|                   1|\n",
            "|2022-01-11 00:00:00|                   1|\n",
            "|2022-01-12 00:00:00|                   1|\n",
            "|2022-01-13 00:00:00|                   1|\n",
            "|2022-01-14 00:00:00|                   1|\n",
            "|2022-01-15 00:00:00|                   1|\n",
            "|2022-01-16 00:00:00|                   1|\n",
            "|2022-01-17 00:00:00|                   1|\n",
            "|2022-01-18 00:00:00|                   1|\n",
            "|2022-01-19 00:00:00|                   1|\n",
            "|2022-01-20 00:00:00|                   1|\n",
            "+-------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encontrar la diferencia de tiempo entre filas relacionadas usando una función de ventana"
      ],
      "metadata": {
        "id": "sUOWTWcO8nbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "        (1,'start','2021-01-01',100,'A'),\n",
        "        (1,'end','2021-01-31',200,'A'),\n",
        "        (2,'start','2021-03-05 4:53:11',100,'A'),\n",
        "        (2,'end','2021-05-01 05:06:38',200,'A'),\n",
        "]\n",
        "\n",
        "columns = [\"id\",\"session\",\"datetime\",\"station_return\",\"type\"]\n",
        "df = spark.createDataFrame(data=data, schema = columns)\n",
        "df.createOrReplaceTempView(\"window_test\")\n",
        "df.show()"
      ],
      "metadata": {
        "id": "HdPlvvXH8slO",
        "outputId": "be877219-d592-40ca-d712-64f698b42dc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+-------------------+--------------+----+\n",
            "| id|session|           datetime|station_return|type|\n",
            "+---+-------+-------------------+--------------+----+\n",
            "|  1|  start|         2021-01-01|           100|   A|\n",
            "|  1|    end|         2021-01-31|           200|   A|\n",
            "|  2|  start| 2021-03-05 4:53:11|           100|   A|\n",
            "|  2|    end|2021-05-01 05:06:38|           200|   A|\n",
            "+---+-------+-------------------+--------------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql('''\n",
        "SELECT\n",
        "  id,\n",
        "  datetime,\n",
        "  lead(datetime) OVER (PARTITION BY id ORDER BY datetime) as next_datetime,\n",
        "  DATEDIFF(lead(datetime) OVER (PARTITION BY id ORDER BY datetime),datetime) as duration_in_days\n",
        "\n",
        "FROM window_test\n",
        "\n",
        "''').show()"
      ],
      "metadata": {
        "id": "RejdZCfv8wj9",
        "outputId": "1bd117de-a328-4b87-f014-2c30c7ed64b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------------+-------------------+----------------+\n",
            "| id|           datetime|      next_datetime|duration_in_days|\n",
            "+---+-------------------+-------------------+----------------+\n",
            "|  1|         2021-01-01|         2021-01-31|              30|\n",
            "|  1|         2021-01-31|               NULL|            NULL|\n",
            "|  2| 2021-03-05 4:53:11|2021-05-01 05:06:38|              57|\n",
            "|  2|2021-05-01 05:06:38|               NULL|            NULL|\n",
            "+---+-------------------+-------------------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unpivotting (Despivotando)"
      ],
      "metadata": {
        "id": "QzpWKZri9CQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "\n",
        "\n",
        "data = [\n",
        "        ('tim', 10, 9, 8, 5),\n",
        "        ('john', 5, 6, 3, 6),\n",
        "        ('jane', 7, 8, 9, 10),\n",
        "\n",
        "]\n",
        "\n",
        "schema = StructType([\n",
        "   StructField(\"name\", StringType(), True),\n",
        "   StructField(\"experience\", IntegerType(), True),\n",
        "   StructField(\"satisfaction\", IntegerType(), True),\n",
        "   StructField(\"customer_service\", IntegerType(), True),\n",
        "   StructField(\"speed_of_service\", IntegerType(), True)])\n",
        "\n",
        "\n",
        "df = spark.createDataFrame(data, schema=schema)\n",
        "\n",
        "df.show()"
      ],
      "metadata": {
        "id": "c_i2AlK19Hw1",
        "outputId": "372fd6b9-7ace-4341-db78-6bb4b12acb6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----------+------------+----------------+----------------+\n",
            "|name|experience|satisfaction|customer_service|speed_of_service|\n",
            "+----+----------+------------+----------------+----------------+\n",
            "| tim|        10|           9|               8|               5|\n",
            "|john|         5|           6|               3|               6|\n",
            "|jane|         7|           8|               9|              10|\n",
            "+----+----------+------------+----------------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols = ['experience', 'satisfaction', 'customer_service', 'speed_of_service']\n",
        "\n",
        "exprs = f\"\"\"stack({len(cols)}, {\", \".join([f\"'{i}',{i}\" for i in cols])}) as (question,score)\"\"\"\n",
        "\n",
        "unpivotted_df = df.select(\"name\",F.expr(exprs))\n",
        "\n",
        "unpivotted_df.show()"
      ],
      "metadata": {
        "id": "ywYYr0TA9Qyu",
        "outputId": "9d9c1b90-a6a9-4508-bac9-24a5bae3af6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----------------+-----+\n",
            "|name|        question|score|\n",
            "+----+----------------+-----+\n",
            "| tim|      experience|   10|\n",
            "| tim|    satisfaction|    9|\n",
            "| tim|customer_service|    8|\n",
            "| tim|speed_of_service|    5|\n",
            "|john|      experience|    5|\n",
            "|john|    satisfaction|    6|\n",
            "|john|customer_service|    3|\n",
            "|john|speed_of_service|    6|\n",
            "|jane|      experience|    7|\n",
            "|jane|    satisfaction|    8|\n",
            "|jane|customer_service|    9|\n",
            "|jane|speed_of_service|   10|\n",
            "+----+----------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Crear un rango de fechas"
      ],
      "metadata": {
        "id": "yqwURZBZ-D93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "date_range_df = spark.sql(\"SELECT explode(sequence(to_date('2018-01-01'), to_date('2018-03-01'), interval 1 day)) as date\")\n",
        "date_range_df.show()"
      ],
      "metadata": {
        "id": "CBaYzupx-Jie",
        "outputId": "4c48d78a-229b-42d3-86de-b570d0fa2ba7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "|      date|\n",
            "+----------+\n",
            "|2018-01-01|\n",
            "|2018-01-02|\n",
            "|2018-01-03|\n",
            "|2018-01-04|\n",
            "|2018-01-05|\n",
            "|2018-01-06|\n",
            "|2018-01-07|\n",
            "|2018-01-08|\n",
            "|2018-01-09|\n",
            "|2018-01-10|\n",
            "|2018-01-11|\n",
            "|2018-01-12|\n",
            "|2018-01-13|\n",
            "|2018-01-14|\n",
            "|2018-01-15|\n",
            "|2018-01-16|\n",
            "|2018-01-17|\n",
            "|2018-01-18|\n",
            "|2018-01-19|\n",
            "|2018-01-20|\n",
            "+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Concatenar valores de fila después de la agrupación"
      ],
      "metadata": {
        "id": "6zBzO1Mn-P0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = (spark\n",
        "    .createDataFrame([\n",
        "        (1, 'hello',3),\n",
        "        (2, 'hello',5),\n",
        "        (3, 'hello',5),\n",
        "        (3, 'hello',5),\n",
        "        (3, 'hello',5),\n",
        "        ],\n",
        "        [\"id\", \"text\"]))\n",
        "\n",
        "df.createOrReplaceTempView(\"group_array\")\n",
        "\n",
        "df.show()"
      ],
      "metadata": {
        "id": "RqkOf-Bl-SOu",
        "outputId": "399ae780-6a6d-4b7d-c8e0-3cd81051f73a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+---+\n",
            "| id| text| _3|\n",
            "+---+-----+---+\n",
            "|  1|hello|  3|\n",
            "|  2|hello|  5|\n",
            "|  3|hello|  5|\n",
            "|  3|hello|  5|\n",
            "|  3|hello|  5|\n",
            "+---+-----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Devolver cada elemento\n",
        "spark.sql(\"Select g.text, collect_list(g.id) FROM group_array as g GROUP BY 1\").show()"
      ],
      "metadata": {
        "id": "rkAmsLfc-YjG",
        "outputId": "543f8889-2258-4986-fc91-d1b3cadd9cda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------------+\n",
            "| text|collect_list(id)|\n",
            "+-----+----------------+\n",
            "|hello| [1, 2, 3, 3, 3]|\n",
            "+-----+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Devolver lista única\n",
        "spark.sql(\"Select g.text, collect_set(g.id) FROM group_array as g GROUP BY 1\").show()"
      ],
      "metadata": {
        "id": "Nfp54DAX-hM-",
        "outputId": "40bf2a01-812c-4448-9bf0-62026be29b49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---------------+\n",
            "| text|collect_set(id)|\n",
            "+-----+---------------+\n",
            "|hello|      [1, 2, 3]|\n",
            "+-----+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Manejo de valores nulos"
      ],
      "metadata": {
        "id": "NyzjSMIoCXf9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = (spark\n",
        "    .createDataFrame([\n",
        "        (1, 'hello',None),\n",
        "        (2, 'hello',None),\n",
        "        (3, 'hello',5),\n",
        "        (3, 'hello',5),\n",
        "        (3, 'hello',5),\n",
        "        ],\n",
        "        [\"id\", \"text\"]))\n",
        "\n",
        "df.createOrReplaceTempView(\"group_array\")\n",
        "\n",
        "df.show()"
      ],
      "metadata": {
        "id": "JpNyE7DICagu",
        "outputId": "3861afe3-5ed7-47c9-a846-04fa0e35eb40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+----+\n",
            "| id| text|  _3|\n",
            "+---+-----+----+\n",
            "|  1|hello|NULL|\n",
            "|  2|hello|NULL|\n",
            "|  3|hello|   5|\n",
            "|  3|hello|   5|\n",
            "|  3|hello|   5|\n",
            "+---+-----+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"Select * from group_array where _3 IS NOT NULL\").show()"
      ],
      "metadata": {
        "id": "p0w8eL5PCoRG",
        "outputId": "bdc86b71-2399-496a-ef9d-4c628efeb628",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+---+\n",
            "| id| text| _3|\n",
            "+---+-----+---+\n",
            "|  3|hello|  5|\n",
            "|  3|hello|  5|\n",
            "|  3|hello|  5|\n",
            "+---+-----+---+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}